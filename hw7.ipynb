{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5337996f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "plt.style.use('seaborn-white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "225f802b",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "#torchvision 데이터셋의 출력(output)은 [0, 1] 범위를 갖는 PILImage 이미지이므로 \n",
    "#이를 [-1, 1]의 범위로 정규화된 Tensor로 변환합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57646c28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['airplane',\n",
       " 'automobile',\n",
       " 'bird',\n",
       " 'cat',\n",
       " 'deer',\n",
       " 'dog',\n",
       " 'frog',\n",
       " 'horse',\n",
       " 'ship',\n",
       " 'truck']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 4\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', \n",
    "    train=True,\n",
    "    download=True, \n",
    "    transform=transform\n",
    ") \n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    trainset, \n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', \n",
    "    train=False,\n",
    "    download=True, \n",
    "    transform=transform\n",
    ")\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    testset, \n",
    "    batch_size=batch_size,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "classes = trainset.classes\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7115425",
   "metadata": {},
   "outputs": [],
   "source": [
    "class cnn(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        #순서대로 in_channels=3, out_channels=6, kernel_size=5, padding=1입니다.\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5, 1) #rgb의 3색이므로 in_channels=3, padding=1을 주어 정보 축소를 최소화시킵니다.\n",
    "        self.pool = nn.MaxPool2d(2, 2) #pooling의 방법은 max pooling을 이용합니다 stride값은 2로 줍니다.\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5, 1)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120) \n",
    "        self.fc2 = nn.Linear(120, 70)\n",
    "        self.fc3 = nn.Linear(70, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # convoultion # input (32 * 32 * 3)\n",
    "        x = self.pool(F.relu(self.conv1(x))) # ReLu함수를 이용합니다.\n",
    "        x = self.pool(F.relu(self.conv2(x))) # input (5 * 5 * 16)\n",
    "        # fully connected\n",
    "        x = torch.flatten(x, 1) # 배치를 제외한 모든 차원을 평탄화합니다.\n",
    "        x = F.relu(self.fc1(x)) # ReLu함수를 이용합니다.\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = cnn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92586fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss함수는 CrossEntropy를 이용합니다 pytorch에선 softmax와 \n",
    "#cross-entropy를 합쳐놓은 것 을 제공하기 때문에 \n",
    "#맨 마지막 layer가 softmax일 필요가 없습니다. \n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9) \n",
    "#momentum을 주어 localminimum에 빠지기 않게함 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d05e4cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  4000] loss: 2.058\n",
      "[1,  8000] loss: 1.628\n",
      "[1, 12000] loss: 1.498\n",
      "[2,  4000] loss: 1.384\n",
      "[2,  8000] loss: 1.343\n",
      "[2, 12000] loss: 1.310\n",
      "[3,  4000] loss: 1.230\n",
      "[3,  8000] loss: 1.200\n",
      "[3, 12000] loss: 1.194\n",
      "[4,  4000] loss: 1.099\n",
      "[4,  8000] loss: 1.111\n",
      "[4, 12000] loss: 1.112\n",
      "[5,  4000] loss: 1.023\n",
      "[5,  8000] loss: 1.035\n",
      "[5, 12000] loss: 1.047\n",
      "[6,  4000] loss: 0.967\n",
      "[6,  8000] loss: 0.969\n",
      "[6, 12000] loss: 0.994\n",
      "[7,  4000] loss: 0.898\n",
      "[7,  8000] loss: 0.937\n",
      "[7, 12000] loss: 0.942\n",
      "[8,  4000] loss: 0.865\n",
      "[8,  8000] loss: 0.903\n",
      "[8, 12000] loss: 0.905\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(8):   # 훈련데이터의 훈련을 8번 시킵니다.\n",
    "\n",
    "    running_loss = 0.0 #오차를 초기화합니다.\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        # loader 데이터를 가져와서 하나씩 분할합니다.\n",
    "        inputs, labels = data #왼쪽은 그림, 오른쪽은 분류입니다 각 4개입니다.\n",
    "\n",
    "        # parameter의 gradient를 0으로 만듭니다.\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 순전파와 역전파를 최적화를 합니다. (오차역전파)\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() # loss값을 출력합니다.\n",
    "        if i % 4000 == 3999:    # 4000개의 벤치마다 값을 표기합니다.\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 4000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10a92cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './cifar_net.pth'\n",
    "torch.save(model.state_dict(), PATH) #학습한 모델을 저장합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "14c56a1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = cnn()\n",
    "model.load_state_dict(torch.load(PATH)) #저장했던 모델들을 불러옵니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6699e7b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 63 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "# 출력에 대한 변화도 계산의 필요가 없음(학습 중X)\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        # 신경망에 이미지를 값을 입력하여 출력을 계산합니다.\n",
    "        outputs = model(images)\n",
    "        # 가장 높은 값를 갖는 분류(class)를 정답으로 선택합니다.\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy : %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9255fb76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy airplane is: 78.3 %\n",
      "Accuracy automobile is: 74.3 %\n",
      "Accuracy bird  is: 44.3 %\n",
      "Accuracy cat   is: 45.0 %\n",
      "Accuracy deer  is: 65.3 %\n",
      "Accuracy dog   is: 44.9 %\n",
      "Accuracy frog  is: 75.3 %\n",
      "Accuracy horse is: 65.8 %\n",
      "Accuracy ship  is: 73.7 %\n",
      "Accuracy truck is: 71.8 %\n"
     ]
    }
   ],
   "source": [
    "# 분류에 대한 예측값 계산을 준비합니다.\n",
    "correct_pred = {classname: 0 for classname in classes}\n",
    "total_pred = {classname: 0 for classname in classes}\n",
    "\n",
    "# 변화도는 필요하지 않습니다.\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        outputs = model(images)\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "        # 분류별로 맞춘 예측 수를 정렬합니다.\n",
    "        for label, prediction in zip(labels, predictions):\n",
    "            if label == prediction:\n",
    "                correct_pred[classes[label]] += 1\n",
    "            total_pred[classes[label]] += 1\n",
    "\n",
    "\n",
    "# 분류별 accuracy를 출력합니다\n",
    "for classname, correct_count in correct_pred.items():\n",
    "    accuracy = 100 * float(correct_count) / total_pred[classname]\n",
    "    print(\"Accuracy {:5s} is: {:.1f} %\".format(classname,\n",
    "                                                   accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6320884e",
   "metadata": {},
   "source": [
    "## 보고서"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f45db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CNN을 이용하여 CIFar-10 이미지를 분류하는 작업, 방법을 running시키는것이 목적이다.\n",
    "#우선 작업에 쓰일 pytorch와 각종 라이브러리를 불러오고 torchvision으로 부터\n",
    "#데이터들을 불러온다. torchvision 데이터의 출력은 [0, 1] 범위를 갖는 PILImage 이미지 \n",
    "#이므로 우선 이를 [-1, 1]의 범위로 정규화된 Tensor로 변환한다.\n",
    "#banch size는 4로 설정해주고(데이터 처리량이 많으므로) dataset으로 부터 load되는\n",
    "#데이터들을 설정해준다. (셔플과 정규화 텐서로 변환) 해당 이미지는 컬러이므로 \n",
    "#in channel을 3으로 설정하고 kernel 행렬은 5x5, pading은 1, kernel의 stride값은 2로\n",
    "#설정해준다. 이때 pooling은 max pooling 방법을 이용해주며 convoultion이 끝날 때마다\n",
    "#출력되는 out channel은 각각 6, 16으로 해준다 convoultion과 fully connected은\n",
    "#ReLu함수가 적합하다고 판단하여 해당 함수를 이용해주었고 loss함수는 CrossEntropy를 \n",
    "#이용해주었다 이때 localminimum에 빠지기 않게하기 위해 mometum값을 주었다.\n",
    "#훈련은 8번 이상부터 loss값이 수렴하여 그 이상은 의미가 없다 판단하여 8회 학습을\n",
    "#시켜주었고 오차역전파를 해주어 정확도를 올려줍니다. 최종적으로 출력값이 도출될 때\n",
    "#출력에서 가장 높은 값을 갖는 분류를 정답으로 선택해주며 전체적인 정답률을 도츌하고\n",
    "#각 분류별로 맞춘 예측 수를 이용하여 분류별로 맞춘 정답률을 기재해줍니다.\n",
    "#해당 결과로 미루어보아 cnn을 이용한 이미지 분류는 모든 이미지가 동등한 정답률을\n",
    "#갖지않음을 알 수 있습니다. 또한 각 분류 별로 정답률이 크게 차이가 나는 것을 볼 때\n",
    "#정답률이 낮은 그룹과 높은 그룹을 분석하여 해당 사유에 대해 고찰하면 두 그룹이 갖는\n",
    "#두드러진 공통점과 차이점, 혹은 각각의 한계에 대해 알 수 있으므로 cnn의 성능 개선에\n",
    "#큰 영향을 줄 것으로 판단됩니다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
